{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b189330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b8c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the symmetric mean absolute percentage error between the true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): true values of the target variable.\n",
    "        y_pred (array-like): predicted values of the target variable.\n",
    "    \n",
    "    Returns:\n",
    "        smape (float): symmetric mean absolute percentage error between y_true and y_pred.\n",
    "    \"\"\"\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d9ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged_df_clean dataset\n",
    "merged_df_clean = pd.read_csv('merged_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d739d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regressors to evaluate\n",
    "regressors = [LGBMRegressor(), XGBRegressor(), RandomForestRegressor(), ElasticNet(), Lasso(), Ridge(), LinearRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9592668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store the results\n",
    "results_df = pd.DataFrame(columns=['cfips', 'model_name', 'smape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba42484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each cfips\n",
    "for cfips in merged_df_clean['cfips'].unique():\n",
    "\n",
    "    # filter the data for the current cfips\n",
    "    cfips_data = merged_df_clean[merged_df_clean['cfips'] == cfips]\n",
    "\n",
    "    # perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cfips_data[['pct_bb', 'pct_college', 'active']], cfips_data['microbusiness_density'], test_size=0.2, random_state=92)\n",
    "\n",
    "    # initialize the models\n",
    "    lgbm_model = LGBMRegressor()\n",
    "    xgb_model = XGBRegressor()\n",
    "    rf_model = RandomForestRegressor()\n",
    "    en_model = ElasticNet()\n",
    "    lasso_model = Lasso()\n",
    "    ridge_model = Ridge()\n",
    "    lr_model = LinearRegression()\n",
    "\n",
    "    # perform cross-validation on each model\n",
    "    models = [('LGBM', LGBMRegressor(random_state=92)),\n",
    "          ('XGB', XGBRegressor(random_state=92)),\n",
    "          ('RandomForest', RandomForestRegressor(n_estimators=10, random_state=92)),\n",
    "          ('ElasticNet', ElasticNet(random_state=92)),\n",
    "          ('Lasso', Lasso(random_state=92)),\n",
    "          ('Ridge', Ridge(random_state=92)),\n",
    "          ('LinearRegression', LinearRegression())]\n",
    "    smape_results = []\n",
    "    for name, model in models:\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=92)\n",
    "        smape_scores = []\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            model.fit(X_train_kf, y_train_kf)\n",
    "            y_pred_kf = model.predict(X_val_kf)\n",
    "            smape_score = smape(y_val_kf, y_pred_kf)\n",
    "            smape_scores.append(smape_score)\n",
    "        mean_smape = np.mean(smape_scores)\n",
    "        smape_results.append((name, mean_smape))\n",
    "\n",
    "    # select the best model based on the mean smape\n",
    "    best_model = min(smape_results, key=lambda x: x[1])\n",
    "\n",
    "    # evaluate the best model on the test set\n",
    "    model = next(filter(lambda x: x[0] == best_model[0], models))[1]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    smape_score = smape(y_test, y_pred)\n",
    "\n",
    "    # save the results to the dataframe\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({'cfips': cfips, 'best_model': best_model[0], 'best_smape': best_model[1]}, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e9d00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fe5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to store the results\n",
    "results_df = pd.DataFrame(columns=['cfips', 'best_model', 'best_smape'])\n",
    "\n",
    "# loop through each cfips\n",
    "for cfips in merged_df_clean['cfips'].unique():\n",
    "\n",
    "    # filter the data for the current cfips\n",
    "    cfips_data = merged_df_clean[merged_df_clean['cfips'] == cfips]\n",
    "    \n",
    "    # skip CFIPS with less than 2 samples\n",
    "    if len(cfips_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    # perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cfips_data[['pct_bb', 'pct_college', 'active']], cfips_data['microbusiness_density'], test_size=0.2, random_state=92)\n",
    "\n",
    "    # skip CFIPS with not enough samples for KFold cross-validation\n",
    "    if len(X_train) < 7:\n",
    "        # train and evaluate each model on the entire training set\n",
    "        lgbm_model = LGBMRegressor()\n",
    "        xgb_model = XGBRegressor()\n",
    "        rf_model = RandomForestRegressor()\n",
    "        en_model = ElasticNet()\n",
    "        lasso_model = Lasso()\n",
    "        ridge_model = Ridge()\n",
    "        lr_model = LinearRegression()\n",
    "\n",
    "        models = [('LGBM', lgbm_model), ('XGB', xgb_model), ('RandomForest', rf_model), ('ElasticNet', en_model), ('Lasso', lasso_model), ('Ridge', ridge_model), ('LinearRegression', lr_model)]\n",
    "        smape_results = []\n",
    "        for name, model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            smape_score = smape(y_test, y_pred)\n",
    "            smape_results.append((name, smape_score))\n",
    "\n",
    "        # select the best model based on the test smape\n",
    "        best_model = min(smape_results, key=lambda x: x[1])\n",
    "\n",
    "    else:\n",
    "        # perform cross-validation on each model\n",
    "        lgbm_model = LGBMRegressor()\n",
    "        xgb_model = XGBRegressor()\n",
    "        rf_model = RandomForestRegressor()\n",
    "        en_model = ElasticNet()\n",
    "        lasso_model = Lasso()\n",
    "        ridge_model = Ridge()\n",
    "        lr_model = LinearRegression()\n",
    "\n",
    "        models = [('LGBM', lgbm_model), ('XGB', xgb_model), ('RandomForest', rf_model), ('ElasticNet', en_model), ('Lasso', lasso_model), ('Ridge', ridge_model), ('LinearRegression', lr_model)]\n",
    "        smape_results = []\n",
    "        for name, model in models:\n",
    "            kf = KFold(n_splits=7, shuffle=True, random_state=92)\n",
    "            smape_scores = []\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "                y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "                model.fit(X_train_kf, y_train_kf)\n",
    "                y_pred_kf = model.predict(X_val_kf)\n",
    "                smape_score = smape(y_val_kf, y_pred_kf)\n",
    "                smape_scores.append(smape_score)\n",
    "            mean_smape = np.mean(smape_scores)\n",
    "            smape_results.append((name, mean_smape))\n",
    "\n",
    "        # select the best model based on the mean sm\n",
    "    # select the best model based on the mean smape\n",
    "    best_model = min(smape_results, key=lambda x: x[1])\n",
    "\n",
    "    # evaluate the best model on the test set\n",
    "    model = next(filter(lambda x: x[0] == best_model[0], models))[1]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    smape_score = smape(y_test, y_pred)\n",
    "\n",
    "    # save the results to the dataframe\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({'cfips': cfips, 'best_model': best_model[0], 'best_smape': best_model[1]}, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d09bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = ['pct_bb', 'pct_college', 'pct_foreign_born', 'median_hh_inc', 'pct_it_workers', 'cfips', 'region_code', 'state_code']\n",
    "target = 'microbusiness_density'\n",
    "\n",
    "# Create a Decision Tree regressor model\n",
    "tree = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "# Fit the model to the data\n",
    "tree.fit(merged_df_clean[features], merged_df_clean[target])\n",
    "\n",
    "# Predict the target variable for each row in the data\n",
    "y_pred = tree.predict(merged_df_clean[features])\n",
    "\n",
    "# Add the predicted target variable to the data\n",
    "merged_df_clean['y_pred'] = y_pred\n",
    "\n",
    "# Partition the data into smaller dataframes based on the predicted target variable\n",
    "dfs_dt = []\n",
    "for val, df in merged_df_clean.groupby('y_pred'):\n",
    "    dfs_dt.append(df.drop(columns=['y_pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d48be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       Unnamed: 0            row_id  cfips          county    state  \\\n",
       " 78             97   1005_2019-08-01   1005  barbour county  alabama   \n",
       " 79             98   1005_2019-09-01   1005  barbour county  alabama   \n",
       " 80             99   1005_2019-10-01   1005  barbour county  alabama   \n",
       " 81            100   1005_2019-11-01   1005  barbour county  alabama   \n",
       " 82            101   1005_2019-12-01   1005  barbour county  alabama   \n",
       " ...           ...               ...    ...             ...      ...   \n",
       " 97005      150697  56041_2021-08-01  56041    uinta county  wyoming   \n",
       " 97006      150698  56041_2021-09-01  56041    uinta county  wyoming   \n",
       " 97007      150699  56041_2021-10-01  56041    uinta county  wyoming   \n",
       " 97008      150700  56041_2021-11-01  56041    uinta county  wyoming   \n",
       " 97009      150701  56041_2021-12-01  56041    uinta county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density  active year_month  year  \\\n",
       " 78            2019-08-01               1.073138     222    2019-08  2019   \n",
       " 79            2019-09-01               0.995794     206    2019-09  2019   \n",
       " 80            2019-10-01               1.160149     240    2019-10  2019   \n",
       " 81            2019-11-01               1.000628     207    2019-11  2019   \n",
       " 82            2019-12-01               1.000628     207    2019-12  2019   \n",
       " ...                  ...                    ...     ...        ...   ...   \n",
       " 97005         2021-08-01               3.439956     499    2021-08  2021   \n",
       " 97006         2021-09-01               3.481318     505    2021-09  2021   \n",
       " 97007         2021-10-01               3.501999     508    2021-10  2021   \n",
       " 97008         2021-11-01               3.481318     505    2021-11  2021   \n",
       " 97009         2021-12-01               3.777747     548    2021-12  2021   \n",
       " \n",
       "        month  pct_bb  pct_college  pct_foreign_born  pct_it_workers  \\\n",
       " 78         8    57.2          7.6               2.7             0.5   \n",
       " 79         9    57.2          7.6               2.7             0.5   \n",
       " 80        10    57.2          7.6               2.7             0.5   \n",
       " 81        11    57.2          7.6               2.7             0.5   \n",
       " 82        12    57.2          7.6               2.7             0.5   \n",
       " ...      ...     ...          ...               ...             ...   \n",
       " 97005      8    89.5         11.1               2.9             1.4   \n",
       " 97006      9    89.5         11.1               2.9             1.4   \n",
       " 97007     10    89.5         11.1               2.9             1.4   \n",
       " 97008     11    89.5         11.1               2.9             1.4   \n",
       " 97009     12    89.5         11.1               2.9             1.4   \n",
       " \n",
       "        median_hh_inc          region  region_code  state_code  \n",
       " 78             33368       southeast            5           1  \n",
       " 79             33368       southeast            5           1  \n",
       " 80             33368       southeast            5           1  \n",
       " 81             33368       southeast            5           1  \n",
       " 82             33368       southeast            5           1  \n",
       " ...              ...             ...          ...         ...  \n",
       " 97005          63403  rocky mountain            7          50  \n",
       " 97006          63403  rocky mountain            7          50  \n",
       " 97007          63403  rocky mountain            7          50  \n",
       " 97008          63403  rocky mountain            7          50  \n",
       " 97009          63403  rocky mountain            7          50  \n",
       " \n",
       " [38892 rows x 19 columns],\n",
       "        Unnamed: 0            row_id  cfips          county    state  \\\n",
       " 0               1   1001_2019-08-01   1001  autauga county  alabama   \n",
       " 1               2   1001_2019-09-01   1001  autauga county  alabama   \n",
       " 2               3   1001_2019-10-01   1001  autauga county  alabama   \n",
       " 3               4   1001_2019-11-01   1001  autauga county  alabama   \n",
       " 4               5   1001_2019-12-01   1001  autauga county  alabama   \n",
       " ...           ...               ...    ...             ...      ...   \n",
       " 97093      150803  56045_2022-06-01  56045   weston county  wyoming   \n",
       " 97094      150804  56045_2022-07-01  56045   weston county  wyoming   \n",
       " 97095      150805  56045_2022-08-01  56045   weston county  wyoming   \n",
       " 97096      150806  56045_2022-09-01  56045   weston county  wyoming   \n",
       " 97097      150807  56045_2022-10-01  56045   weston county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density  active year_month  year  \\\n",
       " 0             2019-08-01               3.007682    1249    2019-08  2019   \n",
       " 1             2019-09-01               2.884870    1198    2019-09  2019   \n",
       " 2             2019-10-01               3.055843    1269    2019-10  2019   \n",
       " 3             2019-11-01               2.993233    1243    2019-11  2019   \n",
       " 4             2019-12-01               2.993233    1243    2019-12  2019   \n",
       " ...                  ...                    ...     ...        ...   ...   \n",
       " 97093         2022-06-01               1.803249     101    2022-06  2022   \n",
       " 97094         2022-07-01               1.803249     101    2022-07  2022   \n",
       " 97095         2022-08-01               1.785395     100    2022-08  2022   \n",
       " 97096         2022-09-01               1.785395     100    2022-09  2022   \n",
       " 97097         2022-10-01               1.785395     100    2022-10  2022   \n",
       " \n",
       "        month  pct_bb  pct_college  pct_foreign_born  pct_it_workers  \\\n",
       " 0          8    76.6         14.5               2.1             1.3   \n",
       " 1          9    76.6         14.5               2.1             1.3   \n",
       " 2         10    76.6         14.5               2.1             1.3   \n",
       " 3         11    76.6         14.5               2.1             1.3   \n",
       " 4         12    76.6         14.5               2.1             1.3   \n",
       " ...      ...     ...          ...               ...             ...   \n",
       " 97093      6    79.7         12.7               2.3             0.0   \n",
       " 97094      7    79.7         12.7               2.3             0.0   \n",
       " 97095      8    79.7         12.7               2.3             0.0   \n",
       " 97096      9    79.7         12.7               2.3             0.0   \n",
       " 97097     10    79.7         12.7               2.3             0.0   \n",
       " \n",
       "        median_hh_inc          region  region_code  state_code  \n",
       " 0              55317       southeast            5           1  \n",
       " 1              55317       southeast            5           1  \n",
       " 2              55317       southeast            5           1  \n",
       " 3              55317       southeast            5           1  \n",
       " 4              55317       southeast            5           1  \n",
       " ...              ...             ...          ...         ...  \n",
       " 97093          53333  rocky mountain            7          50  \n",
       " 97094          53333  rocky mountain            7          50  \n",
       " 97095          53333  rocky mountain            7          50  \n",
       " 97096          53333  rocky mountain            7          50  \n",
       " 97097          53333  rocky mountain            7          50  \n",
       " \n",
       " [24857 rows x 19 columns],\n",
       "        Unnamed: 0            row_id  cfips           county    state  \\\n",
       " 5               6   1001_2020-01-01   1001   autauga county  alabama   \n",
       " 6               7   1001_2020-02-01   1001   autauga county  alabama   \n",
       " 7               8   1001_2020-03-01   1001   autauga county  alabama   \n",
       " 8               9   1001_2020-04-01   1001   autauga county  alabama   \n",
       " 9              10   1001_2020-05-01   1001   autauga county  alabama   \n",
       " ...           ...               ...    ...              ...      ...   \n",
       " 97054      150755  56043_2022-06-01  56043  washakie county  wyoming   \n",
       " 97055      150756  56043_2022-07-01  56043  washakie county  wyoming   \n",
       " 97056      150757  56043_2022-08-01  56043  washakie county  wyoming   \n",
       " 97057      150758  56043_2022-09-01  56043  washakie county  wyoming   \n",
       " 97058      150759  56043_2022-10-01  56043  washakie county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density  active year_month  year  \\\n",
       " 5             2020-01-01               2.969090    1242    2020-01  2020   \n",
       " 6             2020-02-01               2.909326    1217    2020-02  2020   \n",
       " 7             2020-03-01               2.933231    1227    2020-03  2020   \n",
       " 8             2020-04-01               3.000167    1255    2020-04  2020   \n",
       " 9             2020-05-01               3.004948    1257    2020-05  2020   \n",
       " ...                  ...                    ...     ...        ...   ...   \n",
       " 97054         2022-06-01               3.126551     189    2022-06  2022   \n",
       " 97055         2022-07-01               3.225807     195    2022-07  2022   \n",
       " 97056         2022-08-01               3.209264     194    2022-08  2022   \n",
       " 97057         2022-09-01               3.209264     194    2022-09  2022   \n",
       " 97058         2022-10-01               3.126551     189    2022-10  2022   \n",
       " \n",
       "        month  pct_bb  pct_college  pct_foreign_born  pct_it_workers  \\\n",
       " 5          1    78.9         15.9               2.0             1.1   \n",
       " 6          2    78.9         15.9               2.0             1.1   \n",
       " 7          3    78.9         15.9               2.0             1.1   \n",
       " 8          4    78.9         15.9               2.0             1.1   \n",
       " 9          5    78.9         15.9               2.0             1.1   \n",
       " ...      ...     ...          ...               ...             ...   \n",
       " 97054      6    82.8         15.0               2.2             0.9   \n",
       " 97055      7    82.8         15.0               2.2             0.9   \n",
       " 97056      8    82.8         15.0               2.2             0.9   \n",
       " 97057      9    82.8         15.0               2.2             0.9   \n",
       " 97058     10    82.8         15.0               2.2             0.9   \n",
       " \n",
       "        median_hh_inc          region  region_code  state_code  \n",
       " 5              58786       southeast            5           1  \n",
       " 6              58786       southeast            5           1  \n",
       " 7              58786       southeast            5           1  \n",
       " 8              58786       southeast            5           1  \n",
       " 9              58786       southeast            5           1  \n",
       " ...              ...             ...          ...         ...  \n",
       " 97054          57306  rocky mountain            7          50  \n",
       " 97055          57306  rocky mountain            7          50  \n",
       " 97056          57306  rocky mountain            7          50  \n",
       " 97057          57306  rocky mountain            7          50  \n",
       " 97058          57306  rocky mountain            7          50  \n",
       " \n",
       " [20466 rows x 19 columns],\n",
       "        Unnamed: 0            row_id  cfips             county    state  \\\n",
       " 1348         1746   1073_2021-01-01   1073   jefferson county  alabama   \n",
       " 1349         1747   1073_2021-02-01   1073   jefferson county  alabama   \n",
       " 1350         1748   1073_2021-03-01   1073   jefferson county  alabama   \n",
       " 1351         1749   1073_2021-04-01   1073   jefferson county  alabama   \n",
       " 1352         1750   1073_2021-05-01   1073   jefferson county  alabama   \n",
       " ...           ...               ...    ...                ...      ...   \n",
       " 96966      150601  56037_2021-08-01  56037  sweetwater county  wyoming   \n",
       " 96967      150602  56037_2021-09-01  56037  sweetwater county  wyoming   \n",
       " 96968      150603  56037_2021-10-01  56037  sweetwater county  wyoming   \n",
       " 96969      150604  56037_2021-11-01  56037  sweetwater county  wyoming   \n",
       " 96970      150605  56037_2021-12-01  56037  sweetwater county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density  active year_month  year  \\\n",
       " 1348          2021-01-01               6.216286   31610    2021-01  2021   \n",
       " 1349          2021-02-01               6.120514   31123    2021-02  2021   \n",
       " 1350          2021-03-01               6.167122   31360    2021-03  2021   \n",
       " 1351          2021-04-01               6.269579   31881    2021-04  2021   \n",
       " 1352          2021-05-01               6.251881   31791    2021-05  2021   \n",
       " ...                  ...                    ...     ...        ...   ...   \n",
       " 96966         2021-08-01               3.452806    1104    2021-08  2021   \n",
       " 96967         2021-09-01               3.362107    1075    2021-09  2021   \n",
       " 96968         2021-10-01               3.255770    1041    2021-10  2021   \n",
       " 96969         2021-11-01               3.093138     989    2021-11  2021   \n",
       " 96970         2021-12-01               3.039970     972    2021-12  2021   \n",
       " \n",
       "        month  pct_bb  pct_college  pct_foreign_born  pct_it_workers  \\\n",
       " 1348       1    79.4         20.4               4.1             2.5   \n",
       " 1349       2    79.4         20.4               4.1             2.5   \n",
       " 1350       3    79.4         20.4               4.1             2.5   \n",
       " 1351       4    79.4         20.4               4.1             2.5   \n",
       " 1352       5    79.4         20.4               4.1             2.5   \n",
       " ...      ...     ...          ...               ...             ...   \n",
       " 96966      8    84.0         14.8               4.7             1.0   \n",
       " 96967      9    84.0         14.8               4.7             1.0   \n",
       " 96968     10    84.0         14.8               4.7             1.0   \n",
       " 96969     11    84.0         14.8               4.7             1.0   \n",
       " 96970     12    84.0         14.8               4.7             1.0   \n",
       " \n",
       "        median_hh_inc          region  region_code  state_code  \n",
       " 1348           53901       southeast            5           1  \n",
       " 1349           53901       southeast            5           1  \n",
       " 1350           53901       southeast            5           1  \n",
       " 1351           53901       southeast            5           1  \n",
       " 1352           53901       southeast            5           1  \n",
       " ...              ...             ...          ...         ...  \n",
       " 96966          74843  rocky mountain            7          50  \n",
       " 96967          74843  rocky mountain            7          50  \n",
       " 96968          74843  rocky mountain            7          50  \n",
       " 96969          74843  rocky mountain            7          50  \n",
       " 96970          74843  rocky mountain            7          50  \n",
       " \n",
       " [12883 rows x 19 columns]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e710af2",
   "metadata": {},
   "source": [
    "to partition the data based on the continuous target variable without converting it to a categorical variable, you can use regression trees instead of classification trees. RandomForestRegressor is the regression equivalent of RandomForestClassifier in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec13b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = ['pct_bb', 'pct_college', 'pct_foreign_born', 'median_hh_inc', 'pct_it_workers', 'cfips', 'region_code', 'state_code']\n",
    "target = 'microbusiness_density'\n",
    "\n",
    "# Create a Random Forest regressor model with 10 trees\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=92)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(merged_df_clean[features], merged_df_clean[target])\n",
    "\n",
    "# Predict the target variable for each row in the data\n",
    "y_pred = rf.predict(merged_df_clean[features])\n",
    "\n",
    "# Add the predicted target variable to the data\n",
    "merged_df_clean['y_pred'] = y_pred\n",
    "\n",
    "# Partition the data into smaller dataframes based on the predicted target variable\n",
    "dfs_rf = []\n",
    "for val, df in merged_df_clean.groupby(pd.cut(merged_df_clean['y_pred'], bins=10)):\n",
    "    dfs_rf.append(df.drop(columns=['y_pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731eabf4",
   "metadata": {},
   "source": [
    "Here, we create a RandomForestRegressor model with 10 trees, and fit it to the data using the 'microbusiness_density' variable. We use the model to predict the target variable for each row in the data, and add the predicted values as a new column in the dataframe.\n",
    "\n",
    "Then, we partition the data into smaller dataframes based on the predicted target variable using the groupby() method in pandas, and pd.cut() function to divide the range of predicted values into 10 bins. We drop the y_pred column from each dataframe before appending it to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds for the binary classification problem\n",
    "thresholds = [merged_df_clean[target].quantile(0.33), merged_df_clean[target].quantile(0.67)]\n",
    "\n",
    "# Loop over each partition\n",
    "for i, df in enumerate(dfs_dt):\n",
    "    print(f\"Partition {i}\")\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=92)\n",
    "\n",
    "    # Train a random forest classifier\n",
    "    rf = RandomForestRegressor(n_estimators=10, random_state=92)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Classify the predictions using the thresholds\n",
    "    y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "    # Calculate the accuracy, type 1 and type 2 errors, and confusion matrix\n",
    "    if np.sum(y_pred_class) == 0:\n",
    "        tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test >= thresholds[0], y_pred_class)}\")\n",
    "    print(f\"TPR: {tpr}, FPR: {fpr}\")\n",
    "    print(f\"Type 1 error: {fp / (tn + fp)}\")\n",
    "    print(f\"Type 2 error: {fn / (fn + tp)}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(y_test >= thresholds[0], y_pred_class)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9c44a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0\n",
      "Model: LGBM\n",
      "Accuracy: 0.8438102583879676\n",
      "SMAPE: 20.306180301144938\n",
      "TPR: 0.8440860215053764, FPR: 0.15639810426540285\n",
      "Type 1 error: 0.15639810426540285\n",
      "Type 2 error: 0.15591397849462366\n",
      "Confusion matrix:\n",
      "[[3738  693]\n",
      " [ 522 2826]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9096284869520503\n",
      "SMAPE: 11.75940928233866\n",
      "TPR: 0.9124850657108722, FPR: 0.09252990295644324\n",
      "Type 1 error: 0.09252990295644324\n",
      "Type 2 error: 0.08751493428912784\n",
      "Confusion matrix:\n",
      "[[4021  410]\n",
      " [ 293 3055]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9727471397351845\n",
      "SMAPE: 3.6139251529715\n",
      "TPR: 0.9716248506571087, FPR: 0.026404874746106973\n",
      "Type 1 error: 0.026404874746106973\n",
      "Type 2 error: 0.028375149342891277\n",
      "Confusion matrix:\n",
      "[[4314  117]\n",
      " [  95 3253]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.6400565625401723\n",
      "SMAPE: 34.618915319382225\n",
      "TPR: 0.6833930704898447, FPR: 0.3926878808395396\n",
      "Type 1 error: 0.3926878808395396\n",
      "Type 2 error: 0.31660692951015534\n",
      "Confusion matrix:\n",
      "[[2691 1740]\n",
      " [1060 2288]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.6342717572952822\n",
      "SMAPE: 34.93806684270428\n",
      "TPR: 0.6666666666666666, FPR: 0.3902053712480253\n",
      "Type 1 error: 0.3902053712480253\n",
      "Type 2 error: 0.3333333333333333\n",
      "Confusion matrix:\n",
      "[[2702 1729]\n",
      " [1116 2232]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.6856922483609719\n",
      "SMAPE: 32.32389894154523\n",
      "TPR: 0.7461170848267622, FPR: 0.35996389076957797\n",
      "Type 1 error: 0.35996389076957797\n",
      "Type 2 error: 0.25388291517323774\n",
      "Confusion matrix:\n",
      "[[2836 1595]\n",
      " [ 850 2498]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.6856922483609719\n",
      "SMAPE: 32.32390011004467\n",
      "TPR: 0.7461170848267622, FPR: 0.35996389076957797\n",
      "Type 1 error: 0.35996389076957797\n",
      "Type 2 error: 0.25388291517323774\n",
      "Confusion matrix:\n",
      "[[2836 1595]\n",
      " [ 850 2498]]\n",
      "\n",
      "Partition 1\n",
      "Model: LGBM\n",
      "Accuracy: 0.8471440064360418\n",
      "SMAPE: 17.410390770115402\n",
      "TPR: 0.9808102345415778, FPR: 0.5639344262295082\n",
      "Type 1 error: 0.5639344262295082\n",
      "Type 2 error: 0.019189765458422176\n",
      "Confusion matrix:\n",
      "[[ 532  688]\n",
      " [  72 3680]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9432823813354787\n",
      "SMAPE: 8.00433181855996\n",
      "TPR: 0.9848081023454158, FPR: 0.18442622950819673\n",
      "Type 1 error: 0.18442622950819673\n",
      "Type 2 error: 0.015191897654584221\n",
      "Confusion matrix:\n",
      "[[ 995  225]\n",
      " [  57 3695]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9802896218825422\n",
      "SMAPE: 3.2539371063431486\n",
      "TPR: 0.9898720682302772, FPR: 0.04918032786885246\n",
      "Type 1 error: 0.04918032786885246\n",
      "Type 2 error: 0.010127931769722815\n",
      "Confusion matrix:\n",
      "[[1160   60]\n",
      " [  38 3714]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.754827031375704\n",
      "SMAPE: 34.43970276681718\n",
      "TPR: 1.0, FPR: 0.9991803278688525\n",
      "Type 1 error: 0.9991803278688525\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   1 1219]\n",
      " [   0 3752]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.7546259050683829\n",
      "SMAPE: 35.941535985964144\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0 1220]\n",
      " [   0 3752]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.7670957361222848\n",
      "SMAPE: 32.46163635656927\n",
      "TPR: 0.990405117270789, FPR: 0.919672131147541\n",
      "Type 1 error: 0.919672131147541\n",
      "Type 2 error: 0.009594882729211088\n",
      "Confusion matrix:\n",
      "[[  98 1122]\n",
      " [  36 3716]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.7670957361222848\n",
      "SMAPE: 32.46160399677549\n",
      "TPR: 0.990405117270789, FPR: 0.919672131147541\n",
      "Type 1 error: 0.919672131147541\n",
      "Type 2 error: 0.009594882729211088\n",
      "Confusion matrix:\n",
      "[[  98 1122]\n",
      " [  36 3716]]\n",
      "\n",
      "Partition 2\n",
      "Model: LGBM\n",
      "Accuracy: 0.8883732291157792\n",
      "SMAPE: 16.34367987243351\n",
      "TPR: 0.9927388905024688, FPR: 0.663594470046083\n",
      "Type 1 error: 0.663594470046083\n",
      "Type 2 error: 0.007261109497531223\n",
      "Confusion matrix:\n",
      "[[ 219  432]\n",
      " [  25 3418]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9474841231069858\n",
      "SMAPE: 7.232079063779462\n",
      "TPR: 0.9875108916642463, FPR: 0.2642089093701997\n",
      "Type 1 error: 0.2642089093701997\n",
      "Type 2 error: 0.012489108335753703\n",
      "Confusion matrix:\n",
      "[[ 479  172]\n",
      " [  43 3400]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9814362481680508\n",
      "SMAPE: 3.170988806667623\n",
      "TPR: 0.9889631135637525, FPR: 0.05837173579109063\n",
      "Type 1 error: 0.05837173579109063\n",
      "Type 2 error: 0.01103688643624746\n",
      "Confusion matrix:\n",
      "[[ 613   38]\n",
      " [  38 3405]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.8409868099658037\n",
      "SMAPE: 37.766631558105786\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  651]\n",
      " [   0 3443]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.8409868099658037\n",
      "SMAPE: 38.7988942819885\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  651]\n",
      " [   0 3443]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.8431851489985345\n",
      "SMAPE: 34.60586265332106\n",
      "TPR: 0.9968051118210862, FPR: 0.9692780337941628\n",
      "Type 1 error: 0.9692780337941628\n",
      "Type 2 error: 0.003194888178913738\n",
      "Confusion matrix:\n",
      "[[  20  631]\n",
      " [  11 3432]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.8431851489985345\n",
      "SMAPE: 34.60579777243087\n",
      "TPR: 0.9968051118210862, FPR: 0.9692780337941628\n",
      "Type 1 error: 0.9692780337941628\n",
      "Type 2 error: 0.003194888178913738\n",
      "Confusion matrix:\n",
      "[[  20  631]\n",
      " [  11 3432]]\n",
      "\n",
      "Partition 3\n",
      "Model: LGBM\n",
      "Accuracy: 0.9755529685681025\n",
      "SMAPE: 8.18848746483556\n",
      "TPR: 0.996328029375765, FPR: 0.42857142857142855\n",
      "Type 1 error: 0.42857142857142855\n",
      "Type 2 error: 0.0036719706242350062\n",
      "Confusion matrix:\n",
      "[[  72   54]\n",
      " [   9 2442]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9926270857586341\n",
      "SMAPE: 3.0235519383373974\n",
      "TPR: 0.9983680130558955, FPR: 0.11904761904761904\n",
      "Type 1 error: 0.11904761904761904\n",
      "Type 2 error: 0.0016319869441044472\n",
      "Confusion matrix:\n",
      "[[ 111   15]\n",
      " [   4 2447]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.996895615056267\n",
      "SMAPE: 2.0111335728330193\n",
      "TPR: 0.9983680130558955, FPR: 0.031746031746031744\n",
      "Type 1 error: 0.031746031746031744\n",
      "Type 2 error: 0.0016319869441044472\n",
      "Confusion matrix:\n",
      "[[ 122    4]\n",
      " [   4 2447]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.9511059371362048\n",
      "SMAPE: 30.271709216136426\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   0 2451]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.9511059371362048\n",
      "SMAPE: 30.732884684514328\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   0 2451]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.9491656965463717\n",
      "SMAPE: 27.36115729283564\n",
      "TPR: 0.9979600163198694, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.002039983680130559\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   5 2446]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.9491656965463717\n",
      "SMAPE: 27.360957058888026\n",
      "TPR: 0.9979600163198694, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.002039983680130559\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   5 2446]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the thresholds for the binary classification problem\n",
    "thresholds = [merged_df_clean[target].quantile(0.33), merged_df_clean[target].quantile(0.67)]\n",
    "\n",
    "# Define a list of models to evaluate\n",
    "models = [('LGBM', LGBMRegressor(random_state=92)),\n",
    "          ('XGB', XGBRegressor(random_state=92)),\n",
    "          ('RandomForest', RandomForestRegressor(n_estimators=10, random_state=92)),\n",
    "          ('ElasticNet', ElasticNet(random_state=92)),\n",
    "          ('Lasso', Lasso(random_state=92)),\n",
    "          ('Ridge', Ridge(random_state=92)),\n",
    "          ('LinearRegression', LinearRegression())]\n",
    "\n",
    "# Loop over each partition\n",
    "for i, df in enumerate(dfs_dt):\n",
    "    print(f\"Partition {i}\")\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=92)\n",
    "    \n",
    "    # Loop over each model\n",
    "    for model_name, model in models:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the target variable for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Classify the predictions using the thresholds\n",
    "        y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "        # Calculate the evaluation metrics\n",
    "        if np.sum(y_pred_class) == 0:\n",
    "            tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        \n",
    "        # Calculate SMAPE\n",
    "        smape_score = smape(y_test, y_pred)\n",
    "        \n",
    "        \n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test >= thresholds[0], y_pred_class)}\")\n",
    "        print(f\"SMAPE: {smape_score}\")\n",
    "        print(f\"TPR: {tpr}, FPR: {fpr}\")\n",
    "        print(f\"Type 1 error: {fp / (tn + fp)}\")\n",
    "        print(f\"Type 2 error: {fn / (fn + tp)}\")\n",
    "        print(f\"Confusion matrix:\\n{confusion_matrix(y_test >= thresholds[0], y_pred_class)}\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99059670",
   "metadata": {},
   "source": [
    "We first define a list of models to evaluate, which includes the following algorithms: LGBM, XGB, RandomForest, ElasticNet, Lasso, Ridge, and LinearRegression. We then loop over each partition, and for each partition, we loop over each model, train the model on the training set, and make predictions on the test set. We then classify the predictions using the predefined thresholds, calculate the evaluation metrics, and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "039c1386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2655"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_clean['cfips'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee27dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f2a7a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Type 1 Error</th>\n",
       "      <th>Type 2 Error</th>\n",
       "      <th>SMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.155914</td>\n",
       "      <td>20.306180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.909628</td>\n",
       "      <td>0.912485</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>0.087515</td>\n",
       "      <td>11.759409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.972747</td>\n",
       "      <td>0.971625</td>\n",
       "      <td>0.026405</td>\n",
       "      <td>0.026405</td>\n",
       "      <td>0.028375</td>\n",
       "      <td>3.613925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.640057</td>\n",
       "      <td>0.683393</td>\n",
       "      <td>0.392688</td>\n",
       "      <td>0.392688</td>\n",
       "      <td>0.316607</td>\n",
       "      <td>34.618915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.634272</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.390205</td>\n",
       "      <td>0.390205</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>34.938067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.685692</td>\n",
       "      <td>0.746117</td>\n",
       "      <td>0.359964</td>\n",
       "      <td>0.359964</td>\n",
       "      <td>0.253883</td>\n",
       "      <td>32.323899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.685692</td>\n",
       "      <td>0.746117</td>\n",
       "      <td>0.359964</td>\n",
       "      <td>0.359964</td>\n",
       "      <td>0.253883</td>\n",
       "      <td>32.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.847144</td>\n",
       "      <td>0.980810</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.019190</td>\n",
       "      <td>17.410391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.943282</td>\n",
       "      <td>0.984808</td>\n",
       "      <td>0.184426</td>\n",
       "      <td>0.184426</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>8.004332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.980290</td>\n",
       "      <td>0.989872</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>3.253937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.754827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.439703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.754626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.941536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.767096</td>\n",
       "      <td>0.990405</td>\n",
       "      <td>0.919672</td>\n",
       "      <td>0.919672</td>\n",
       "      <td>0.009595</td>\n",
       "      <td>32.461636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.767096</td>\n",
       "      <td>0.990405</td>\n",
       "      <td>0.919672</td>\n",
       "      <td>0.919672</td>\n",
       "      <td>0.009595</td>\n",
       "      <td>32.461604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.888373</td>\n",
       "      <td>0.992739</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>16.343680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.947484</td>\n",
       "      <td>0.987511</td>\n",
       "      <td>0.264209</td>\n",
       "      <td>0.264209</td>\n",
       "      <td>0.012489</td>\n",
       "      <td>7.232079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.981436</td>\n",
       "      <td>0.988963</td>\n",
       "      <td>0.058372</td>\n",
       "      <td>0.058372</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>3.170989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.840987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.766632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.840987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.798894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.843185</td>\n",
       "      <td>0.996805</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>34.605863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.843185</td>\n",
       "      <td>0.996805</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>34.605798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.975553</td>\n",
       "      <td>0.996328</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>8.188487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.992627</td>\n",
       "      <td>0.998368</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>3.023552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>0.998368</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>2.011134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.951106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.271709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.951106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.732885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.949166</td>\n",
       "      <td>0.997960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>27.361157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.949166</td>\n",
       "      <td>0.997960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>27.360957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Partition             Model  Accuracy       TPR       FPR  Type 1 Error  \\\n",
       "0           0              LGBM  0.843810  0.844086  0.156398      0.156398   \n",
       "1           0               XGB  0.909628  0.912485  0.092530      0.092530   \n",
       "2           0      RandomForest  0.972747  0.971625  0.026405      0.026405   \n",
       "3           0        ElasticNet  0.640057  0.683393  0.392688      0.392688   \n",
       "4           0             Lasso  0.634272  0.666667  0.390205      0.390205   \n",
       "5           0             Ridge  0.685692  0.746117  0.359964      0.359964   \n",
       "6           0  LinearRegression  0.685692  0.746117  0.359964      0.359964   \n",
       "7           1              LGBM  0.847144  0.980810  0.563934      0.563934   \n",
       "8           1               XGB  0.943282  0.984808  0.184426      0.184426   \n",
       "9           1      RandomForest  0.980290  0.989872  0.049180      0.049180   \n",
       "10          1        ElasticNet  0.754827  1.000000  0.999180      0.999180   \n",
       "11          1             Lasso  0.754626  1.000000  1.000000      1.000000   \n",
       "12          1             Ridge  0.767096  0.990405  0.919672      0.919672   \n",
       "13          1  LinearRegression  0.767096  0.990405  0.919672      0.919672   \n",
       "14          2              LGBM  0.888373  0.992739  0.663594      0.663594   \n",
       "15          2               XGB  0.947484  0.987511  0.264209      0.264209   \n",
       "16          2      RandomForest  0.981436  0.988963  0.058372      0.058372   \n",
       "17          2        ElasticNet  0.840987  1.000000  1.000000      1.000000   \n",
       "18          2             Lasso  0.840987  1.000000  1.000000      1.000000   \n",
       "19          2             Ridge  0.843185  0.996805  0.969278      0.969278   \n",
       "20          2  LinearRegression  0.843185  0.996805  0.969278      0.969278   \n",
       "21          3              LGBM  0.975553  0.996328  0.428571      0.428571   \n",
       "22          3               XGB  0.992627  0.998368  0.119048      0.119048   \n",
       "23          3      RandomForest  0.996896  0.998368  0.031746      0.031746   \n",
       "24          3        ElasticNet  0.951106  1.000000  1.000000      1.000000   \n",
       "25          3             Lasso  0.951106  1.000000  1.000000      1.000000   \n",
       "26          3             Ridge  0.949166  0.997960  1.000000      1.000000   \n",
       "27          3  LinearRegression  0.949166  0.997960  1.000000      1.000000   \n",
       "\n",
       "    Type 2 Error      SMAPE  \n",
       "0       0.155914  20.306180  \n",
       "1       0.087515  11.759409  \n",
       "2       0.028375   3.613925  \n",
       "3       0.316607  34.618915  \n",
       "4       0.333333  34.938067  \n",
       "5       0.253883  32.323899  \n",
       "6       0.253883  32.323900  \n",
       "7       0.019190  17.410391  \n",
       "8       0.015192   8.004332  \n",
       "9       0.010128   3.253937  \n",
       "10      0.000000  34.439703  \n",
       "11      0.000000  35.941536  \n",
       "12      0.009595  32.461636  \n",
       "13      0.009595  32.461604  \n",
       "14      0.007261  16.343680  \n",
       "15      0.012489   7.232079  \n",
       "16      0.011037   3.170989  \n",
       "17      0.000000  37.766632  \n",
       "18      0.000000  38.798894  \n",
       "19      0.003195  34.605863  \n",
       "20      0.003195  34.605798  \n",
       "21      0.003672   8.188487  \n",
       "22      0.001632   3.023552  \n",
       "23      0.001632   2.011134  \n",
       "24      0.000000  30.271709  \n",
       "25      0.000000  30.732885  \n",
       "26      0.002040  27.361157  \n",
       "27      0.002040  27.360957  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dataframe to store the results\n",
    "results_list = []\n",
    "\n",
    "# Loop over each partition\n",
    "for i, df in enumerate(dfs_dt):\n",
    "#    print(f\"Partition {i}\")\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=92)\n",
    "    \n",
    "    # Loop over each model\n",
    "    for model_name, model in models:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the target variable for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Classify the predictions using the thresholds\n",
    "        y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "        # Calculate the evaluation metrics\n",
    "        if np.sum(y_pred_class) == 0:\n",
    "            tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        type1_err = fp / (tn + fp)\n",
    "        type2_err = fn / (fn + tp)\n",
    "        \n",
    "        # Calculate SMAPE\n",
    "        smape_score = smape(y_test, y_pred)\n",
    "        \n",
    "        # Add the results to the list\n",
    "        results_list.append({'Partition': i,\n",
    "                             'Model': model_name,\n",
    "                             'Accuracy': accuracy_score(y_test >= thresholds[0], y_pred_class),\n",
    "                             'TPR': tpr,\n",
    "                             'FPR': fpr,\n",
    "                             'Type 1 Error': type1_err,\n",
    "                             'Type 2 Error': type2_err,\n",
    "                             'SMAPE': smape_score})\n",
    "\n",
    "# Create a dataframe from the results list\n",
    "results_df = pd.concat([pd.DataFrame.from_records([r]) for r in results_list], ignore_index=True)\n",
    "\n",
    "# Print the results dataframe\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638df9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
