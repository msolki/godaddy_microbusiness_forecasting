{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b189330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b8c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the symmetric mean absolute percentage error between the true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): true values of the target variable.\n",
    "        y_pred (array-like): predicted values of the target variable.\n",
    "    \n",
    "    Returns:\n",
    "        smape (float): symmetric mean absolute percentage error between y_true and y_pred.\n",
    "    \"\"\"\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d9ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged_df_clean dataset\n",
    "merged_df_clean = pd.read_csv('merged_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87db16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the active column from merged_df_clean dataframe\n",
    "merged_df_clean = merged_df_clean.drop('active', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regressors to evaluate\n",
    "# regressors = [LGBMRegressor(), XGBRegressor(), RandomForestRegressor(), ElasticNet(), Lasso(), Ridge(), LinearRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9592668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store the results\n",
    "# results_df = pd.DataFrame(columns=['cfips', 'model_name', 'smape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba42484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "### DO NOT RUN!!!\n",
    "#\n",
    "# loop through each cfips\n",
    "for cfips in merged_df_clean['cfips'].unique():\n",
    "\n",
    "    # filter the data for the current cfips\n",
    "    cfips_data = merged_df_clean[merged_df_clean['cfips'] == cfips]\n",
    "\n",
    "    # perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cfips_data[['pct_bb', 'pct_college', 'median_hh_inc']], cfips_data['microbusiness_density'], test_size=0.2, random_state=92)\n",
    "\n",
    "    # initialize the models\n",
    "    lgbm_model = LGBMRegressor()\n",
    "    xgb_model = XGBRegressor()\n",
    "    rf_model = RandomForestRegressor()\n",
    "    en_model = ElasticNet()\n",
    "    lasso_model = Lasso()\n",
    "    ridge_model = Ridge()\n",
    "    lr_model = LinearRegression()\n",
    "\n",
    "    # perform cross-validation on each model\n",
    "    models = [('LGBM', LGBMRegressor(random_state=92)),\n",
    "          ('XGB', XGBRegressor(random_state=92)),\n",
    "          ('RandomForest', RandomForestRegressor(n_estimators=10, random_state=92)),\n",
    "          ('ElasticNet', ElasticNet(random_state=92)),\n",
    "          ('Lasso', Lasso(random_state=92)),\n",
    "          ('Ridge', Ridge(random_state=92)),\n",
    "          ('LinearRegression', LinearRegression())]\n",
    "    smape_results = []\n",
    "    for name, model in models:\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=92)\n",
    "        smape_scores = []\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            model.fit(X_train_kf, y_train_kf)\n",
    "            y_pred_kf = model.predict(X_val_kf)\n",
    "            smape_score = smape(y_val_kf, y_pred_kf)\n",
    "            smape_scores.append(smape_score)\n",
    "        mean_smape = np.mean(smape_scores)\n",
    "        smape_results.append((name, mean_smape))\n",
    "\n",
    "    # select the best model based on the mean smape\n",
    "    best_model = min(smape_results, key=lambda x: x[1])\n",
    "\n",
    "    # evaluate the best model on the test set\n",
    "    model = next(filter(lambda x: x[0] == best_model[0], models))[1]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    smape_score = smape(y_test, y_pred)\n",
    "\n",
    "    # save the results to the dataframe\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({'cfips': cfips, 'best_model': best_model[0], 'best_smape': best_model[1]}, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e9d00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541fe5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# create an empty dataframe to store the results\n",
    "results_df = pd.DataFrame(columns=['cfips', 'best_model', 'best_smape'])\n",
    "\n",
    "# loop through each cfips\n",
    "for cfips in merged_df_clean['cfips'].unique():\n",
    "\n",
    "    # filter the data for the current cfips\n",
    "    cfips_data = merged_df_clean[merged_df_clean['cfips'] == cfips]\n",
    "    \n",
    "    # skip CFIPS with less than 2 samples\n",
    "    if len(cfips_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    # perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cfips_data[['pct_bb', 'pct_college', 'median_hh_inc']], cfips_data['microbusiness_density'], test_size=0.2, random_state=92)\n",
    "\n",
    "    # skip CFIPS with not enough samples for KFold cross-validation\n",
    "    if len(X_train) < 7:\n",
    "        # train and evaluate each model on the entire training set\n",
    "        lgbm_model = LGBMRegressor()\n",
    "        xgb_model = XGBRegressor()\n",
    "        rf_model = RandomForestRegressor()\n",
    "        en_model = ElasticNet()\n",
    "        lasso_model = Lasso()\n",
    "        ridge_model = Ridge()\n",
    "        lr_model = LinearRegression()\n",
    "\n",
    "        models = [('LGBM', lgbm_model), ('XGB', xgb_model), ('RandomForest', rf_model), ('ElasticNet', en_model), ('Lasso', lasso_model), ('Ridge', ridge_model), ('LinearRegression', lr_model)]\n",
    "        smape_results = []\n",
    "        for name, model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            smape_score = smape(y_test, y_pred)\n",
    "            smape_results.append((name, smape_score))\n",
    "\n",
    "        # select the best model based on the test smape\n",
    "        best_model = min(smape_results, key=lambda x: x[1])\n",
    "\n",
    "    else:\n",
    "        # perform cross-validation on each model\n",
    "        lgbm_model = LGBMRegressor()\n",
    "        xgb_model = XGBRegressor()\n",
    "        rf_model = RandomForestRegressor()\n",
    "        en_model = ElasticNet()\n",
    "        lasso_model = Lasso()\n",
    "        ridge_model = Ridge()\n",
    "        lr_model = LinearRegression()\n",
    "\n",
    "        models = [('LGBM', lgbm_model), ('XGB', xgb_model), ('RandomForest', rf_model), ('ElasticNet', en_model), ('Lasso', lasso_model), ('Ridge', ridge_model), ('LinearRegression', lr_model)]\n",
    "        smape_results = []\n",
    "        for name, model in models:\n",
    "            kf = KFold(n_splits=7, shuffle=True, random_state=92)\n",
    "            smape_scores = []\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "                y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "                model.fit(X_train_kf, y_train_kf)\n",
    "                y_pred_kf = model.predict(X_val_kf)\n",
    "                smape_score = smape(y_val_kf, y_pred_kf)\n",
    "                smape_scores.append(smape_score)\n",
    "            mean_smape = np.mean(smape_scores)\n",
    "            smape_results.append((name, mean_smape))\n",
    "\n",
    "        # select the best model based on the mean sm\n",
    "    # select the best model based on the mean smape\n",
    "    best_model = min(smape_results, key=lambda x: x[1])\n",
    "\n",
    "    # evaluate the best model on the test set\n",
    "    model = next(filter(lambda x: x[0] == best_model[0], models))[1]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    smape_score = smape(y_test, y_pred)\n",
    "\n",
    "    # save the results to the dataframe\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({'cfips': cfips, 'best_model': best_model[0], 'best_smape': best_model[1]}, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c66f8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cfips</th>\n",
       "      <th>best_model</th>\n",
       "      <th>best_smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.968795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>XGB</td>\n",
       "      <td>2.745682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2.756395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2.393472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.664058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>56035</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.504146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>56037</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.263048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>56041</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>3.647097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>56043</td>\n",
       "      <td>XGB</td>\n",
       "      <td>2.513421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>56045</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.137209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cfips        best_model  best_smape\n",
       "0      1001             Ridge    1.968795\n",
       "1      1003               XGB    2.745682\n",
       "2      1005      RandomForest    2.756395\n",
       "3      1007      RandomForest    2.393472\n",
       "4      1009             Ridge    1.664058\n",
       "...     ...               ...         ...\n",
       "2647  56035      RandomForest    0.504146\n",
       "2648  56037             Ridge    3.263048\n",
       "2649  56041  LinearRegression    3.647097\n",
       "2650  56043               XGB    2.513421\n",
       "2651  56045             Ridge    2.137209\n",
       "\n",
       "[2652 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21d2e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.652000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.921476e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.747265e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.808078e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.421761e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.190530e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.451699e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.316624e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         best_smape\n",
       "count  2.652000e+03\n",
       "mean   2.921476e+00\n",
       "std    2.747265e+00\n",
       "min    1.808078e-15\n",
       "25%    1.421761e+00\n",
       "50%    2.190530e+00\n",
       "75%    3.451699e+00\n",
       "max    4.316624e+01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b064adbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cfips</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pct_bb</th>\n",
       "      <th>pct_college</th>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <th>pct_it_workers</th>\n",
       "      <th>median_hh_inc</th>\n",
       "      <th>region_code</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "      <td>97098.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76394.671178</td>\n",
       "      <td>30762.709634</td>\n",
       "      <td>2.839416</td>\n",
       "      <td>2020.694731</td>\n",
       "      <td>6.684463</td>\n",
       "      <td>73.860246</td>\n",
       "      <td>13.126922</td>\n",
       "      <td>3.038964</td>\n",
       "      <td>1.192352</td>\n",
       "      <td>50142.137253</td>\n",
       "      <td>4.584708</td>\n",
       "      <td>26.666904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42453.150663</td>\n",
       "      <td>14788.640590</td>\n",
       "      <td>1.705118</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>3.390741</td>\n",
       "      <td>7.805318</td>\n",
       "      <td>4.292398</td>\n",
       "      <td>2.395798</td>\n",
       "      <td>0.685869</td>\n",
       "      <td>9877.042305</td>\n",
       "      <td>1.435578</td>\n",
       "      <td>13.791514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0.143384</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22292.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40497.250000</td>\n",
       "      <td>19109.000000</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>68.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>42965.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75954.500000</td>\n",
       "      <td>29201.000000</td>\n",
       "      <td>2.365911</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>74.800000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>49850.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112136.750000</td>\n",
       "      <td>45041.000000</td>\n",
       "      <td>3.648241</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>79.600000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>56533.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150807.000000</td>\n",
       "      <td>56045.000000</td>\n",
       "      <td>8.837772</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>92.800000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>78145.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0         cfips  microbusiness_density          year  \\\n",
       "count   97098.000000  97098.000000           97098.000000  97098.000000   \n",
       "mean    76394.671178  30762.709634               2.839416   2020.694731   \n",
       "std     42453.150663  14788.640590               1.705118      0.989301   \n",
       "min         1.000000   1001.000000               0.143384   2019.000000   \n",
       "25%     40497.250000  19109.000000               1.603922   2020.000000   \n",
       "50%     75954.500000  29201.000000               2.365911   2021.000000   \n",
       "75%    112136.750000  45041.000000               3.648241   2022.000000   \n",
       "max    150807.000000  56045.000000               8.837772   2022.000000   \n",
       "\n",
       "              month        pct_bb   pct_college  pct_foreign_born  \\\n",
       "count  97098.000000  97098.000000  97098.000000      97098.000000   \n",
       "mean       6.684463     73.860246     13.126922          3.038964   \n",
       "std        3.390741      7.805318      4.292398          2.395798   \n",
       "min        1.000000     51.600000      2.200000          0.000000   \n",
       "25%        4.000000     68.900000      9.900000          1.300000   \n",
       "50%        7.000000     74.800000     12.600000          2.300000   \n",
       "75%       10.000000     79.600000     15.900000          4.200000   \n",
       "max       12.000000     92.800000     26.200000         10.700000   \n",
       "\n",
       "       pct_it_workers  median_hh_inc   region_code    state_code  \n",
       "count    97098.000000   97098.000000  97098.000000  97098.000000  \n",
       "mean         1.192352   50142.137253      4.584708     26.666904  \n",
       "std          0.685869    9877.042305      1.435578     13.791514  \n",
       "min          0.000000   22292.000000      1.000000      1.000000  \n",
       "25%          0.700000   42965.000000      4.000000     15.000000  \n",
       "50%          1.100000   49850.000000      5.000000     25.000000  \n",
       "75%          1.600000   56533.000000      5.000000     40.000000  \n",
       "max          3.200000   78145.000000      8.000000     50.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d09bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'row_id', 'cfips', 'county', 'state',\n",
       "       'first_day_of_month', 'microbusiness_density', 'year_month', 'year',\n",
       "       'month', 'pct_bb', 'pct_college', 'pct_foreign_born', 'pct_it_workers',\n",
       "       'median_hh_inc', 'region', 'region_code', 'state_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = ['pct_bb', 'pct_college', 'pct_foreign_born', 'median_hh_inc', 'pct_it_workers', 'cfips', 'region_code', 'state_code']\n",
    "target = 'microbusiness_density'\n",
    "\n",
    "# Create a Decision Tree regressor model\n",
    "tree = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "# Fit the model to the data\n",
    "tree.fit(merged_df_clean[features], merged_df_clean[target])\n",
    "\n",
    "# Predict the target variable for each row in the data\n",
    "y_pred = tree.predict(merged_df_clean[features])\n",
    "\n",
    "# Add the predicted target variable to the data\n",
    "merged_df_clean['y_pred'] = y_pred\n",
    "\n",
    "# Partition the data into smaller dataframes based on the predicted target variable\n",
    "dfs_dt = []\n",
    "for val, df in merged_df_clean.groupby('y_pred'):\n",
    "    dfs_dt.append(df.drop(columns=['y_pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d48be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       Unnamed: 0            row_id  cfips          county    state  \\\n",
       " 78             97   1005_2019-08-01   1005  barbour county  alabama   \n",
       " 79             98   1005_2019-09-01   1005  barbour county  alabama   \n",
       " 80             99   1005_2019-10-01   1005  barbour county  alabama   \n",
       " 81            100   1005_2019-11-01   1005  barbour county  alabama   \n",
       " 82            101   1005_2019-12-01   1005  barbour county  alabama   \n",
       " ...           ...               ...    ...             ...      ...   \n",
       " 97005      150697  56041_2021-08-01  56041    uinta county  wyoming   \n",
       " 97006      150698  56041_2021-09-01  56041    uinta county  wyoming   \n",
       " 97007      150699  56041_2021-10-01  56041    uinta county  wyoming   \n",
       " 97008      150700  56041_2021-11-01  56041    uinta county  wyoming   \n",
       " 97009      150701  56041_2021-12-01  56041    uinta county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density year_month  year  month  \\\n",
       " 78            2019-08-01               1.073138    2019-08  2019      8   \n",
       " 79            2019-09-01               0.995794    2019-09  2019      9   \n",
       " 80            2019-10-01               1.160149    2019-10  2019     10   \n",
       " 81            2019-11-01               1.000628    2019-11  2019     11   \n",
       " 82            2019-12-01               1.000628    2019-12  2019     12   \n",
       " ...                  ...                    ...        ...   ...    ...   \n",
       " 97005         2021-08-01               3.439956    2021-08  2021      8   \n",
       " 97006         2021-09-01               3.481318    2021-09  2021      9   \n",
       " 97007         2021-10-01               3.501999    2021-10  2021     10   \n",
       " 97008         2021-11-01               3.481318    2021-11  2021     11   \n",
       " 97009         2021-12-01               3.777747    2021-12  2021     12   \n",
       " \n",
       "        pct_bb  pct_college  pct_foreign_born  pct_it_workers  median_hh_inc  \\\n",
       " 78       57.2          7.6               2.7             0.5          33368   \n",
       " 79       57.2          7.6               2.7             0.5          33368   \n",
       " 80       57.2          7.6               2.7             0.5          33368   \n",
       " 81       57.2          7.6               2.7             0.5          33368   \n",
       " 82       57.2          7.6               2.7             0.5          33368   \n",
       " ...       ...          ...               ...             ...            ...   \n",
       " 97005    89.5         11.1               2.9             1.4          63403   \n",
       " 97006    89.5         11.1               2.9             1.4          63403   \n",
       " 97007    89.5         11.1               2.9             1.4          63403   \n",
       " 97008    89.5         11.1               2.9             1.4          63403   \n",
       " 97009    89.5         11.1               2.9             1.4          63403   \n",
       " \n",
       "                region  region_code  state_code  \n",
       " 78          southeast            5           1  \n",
       " 79          southeast            5           1  \n",
       " 80          southeast            5           1  \n",
       " 81          southeast            5           1  \n",
       " 82          southeast            5           1  \n",
       " ...               ...          ...         ...  \n",
       " 97005  rocky mountain            7          50  \n",
       " 97006  rocky mountain            7          50  \n",
       " 97007  rocky mountain            7          50  \n",
       " 97008  rocky mountain            7          50  \n",
       " 97009  rocky mountain            7          50  \n",
       " \n",
       " [38892 rows x 18 columns],\n",
       "        Unnamed: 0            row_id  cfips          county    state  \\\n",
       " 0               1   1001_2019-08-01   1001  autauga county  alabama   \n",
       " 1               2   1001_2019-09-01   1001  autauga county  alabama   \n",
       " 2               3   1001_2019-10-01   1001  autauga county  alabama   \n",
       " 3               4   1001_2019-11-01   1001  autauga county  alabama   \n",
       " 4               5   1001_2019-12-01   1001  autauga county  alabama   \n",
       " ...           ...               ...    ...             ...      ...   \n",
       " 97093      150803  56045_2022-06-01  56045   weston county  wyoming   \n",
       " 97094      150804  56045_2022-07-01  56045   weston county  wyoming   \n",
       " 97095      150805  56045_2022-08-01  56045   weston county  wyoming   \n",
       " 97096      150806  56045_2022-09-01  56045   weston county  wyoming   \n",
       " 97097      150807  56045_2022-10-01  56045   weston county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density year_month  year  month  \\\n",
       " 0             2019-08-01               3.007682    2019-08  2019      8   \n",
       " 1             2019-09-01               2.884870    2019-09  2019      9   \n",
       " 2             2019-10-01               3.055843    2019-10  2019     10   \n",
       " 3             2019-11-01               2.993233    2019-11  2019     11   \n",
       " 4             2019-12-01               2.993233    2019-12  2019     12   \n",
       " ...                  ...                    ...        ...   ...    ...   \n",
       " 97093         2022-06-01               1.803249    2022-06  2022      6   \n",
       " 97094         2022-07-01               1.803249    2022-07  2022      7   \n",
       " 97095         2022-08-01               1.785395    2022-08  2022      8   \n",
       " 97096         2022-09-01               1.785395    2022-09  2022      9   \n",
       " 97097         2022-10-01               1.785395    2022-10  2022     10   \n",
       " \n",
       "        pct_bb  pct_college  pct_foreign_born  pct_it_workers  median_hh_inc  \\\n",
       " 0        76.6         14.5               2.1             1.3          55317   \n",
       " 1        76.6         14.5               2.1             1.3          55317   \n",
       " 2        76.6         14.5               2.1             1.3          55317   \n",
       " 3        76.6         14.5               2.1             1.3          55317   \n",
       " 4        76.6         14.5               2.1             1.3          55317   \n",
       " ...       ...          ...               ...             ...            ...   \n",
       " 97093    79.7         12.7               2.3             0.0          53333   \n",
       " 97094    79.7         12.7               2.3             0.0          53333   \n",
       " 97095    79.7         12.7               2.3             0.0          53333   \n",
       " 97096    79.7         12.7               2.3             0.0          53333   \n",
       " 97097    79.7         12.7               2.3             0.0          53333   \n",
       " \n",
       "                region  region_code  state_code  \n",
       " 0           southeast            5           1  \n",
       " 1           southeast            5           1  \n",
       " 2           southeast            5           1  \n",
       " 3           southeast            5           1  \n",
       " 4           southeast            5           1  \n",
       " ...               ...          ...         ...  \n",
       " 97093  rocky mountain            7          50  \n",
       " 97094  rocky mountain            7          50  \n",
       " 97095  rocky mountain            7          50  \n",
       " 97096  rocky mountain            7          50  \n",
       " 97097  rocky mountain            7          50  \n",
       " \n",
       " [24857 rows x 18 columns],\n",
       "        Unnamed: 0            row_id  cfips           county    state  \\\n",
       " 5               6   1001_2020-01-01   1001   autauga county  alabama   \n",
       " 6               7   1001_2020-02-01   1001   autauga county  alabama   \n",
       " 7               8   1001_2020-03-01   1001   autauga county  alabama   \n",
       " 8               9   1001_2020-04-01   1001   autauga county  alabama   \n",
       " 9              10   1001_2020-05-01   1001   autauga county  alabama   \n",
       " ...           ...               ...    ...              ...      ...   \n",
       " 97054      150755  56043_2022-06-01  56043  washakie county  wyoming   \n",
       " 97055      150756  56043_2022-07-01  56043  washakie county  wyoming   \n",
       " 97056      150757  56043_2022-08-01  56043  washakie county  wyoming   \n",
       " 97057      150758  56043_2022-09-01  56043  washakie county  wyoming   \n",
       " 97058      150759  56043_2022-10-01  56043  washakie county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density year_month  year  month  \\\n",
       " 5             2020-01-01               2.969090    2020-01  2020      1   \n",
       " 6             2020-02-01               2.909326    2020-02  2020      2   \n",
       " 7             2020-03-01               2.933231    2020-03  2020      3   \n",
       " 8             2020-04-01               3.000167    2020-04  2020      4   \n",
       " 9             2020-05-01               3.004948    2020-05  2020      5   \n",
       " ...                  ...                    ...        ...   ...    ...   \n",
       " 97054         2022-06-01               3.126551    2022-06  2022      6   \n",
       " 97055         2022-07-01               3.225807    2022-07  2022      7   \n",
       " 97056         2022-08-01               3.209264    2022-08  2022      8   \n",
       " 97057         2022-09-01               3.209264    2022-09  2022      9   \n",
       " 97058         2022-10-01               3.126551    2022-10  2022     10   \n",
       " \n",
       "        pct_bb  pct_college  pct_foreign_born  pct_it_workers  median_hh_inc  \\\n",
       " 5        78.9         15.9               2.0             1.1          58786   \n",
       " 6        78.9         15.9               2.0             1.1          58786   \n",
       " 7        78.9         15.9               2.0             1.1          58786   \n",
       " 8        78.9         15.9               2.0             1.1          58786   \n",
       " 9        78.9         15.9               2.0             1.1          58786   \n",
       " ...       ...          ...               ...             ...            ...   \n",
       " 97054    82.8         15.0               2.2             0.9          57306   \n",
       " 97055    82.8         15.0               2.2             0.9          57306   \n",
       " 97056    82.8         15.0               2.2             0.9          57306   \n",
       " 97057    82.8         15.0               2.2             0.9          57306   \n",
       " 97058    82.8         15.0               2.2             0.9          57306   \n",
       " \n",
       "                region  region_code  state_code  \n",
       " 5           southeast            5           1  \n",
       " 6           southeast            5           1  \n",
       " 7           southeast            5           1  \n",
       " 8           southeast            5           1  \n",
       " 9           southeast            5           1  \n",
       " ...               ...          ...         ...  \n",
       " 97054  rocky mountain            7          50  \n",
       " 97055  rocky mountain            7          50  \n",
       " 97056  rocky mountain            7          50  \n",
       " 97057  rocky mountain            7          50  \n",
       " 97058  rocky mountain            7          50  \n",
       " \n",
       " [20466 rows x 18 columns],\n",
       "        Unnamed: 0            row_id  cfips             county    state  \\\n",
       " 1348         1746   1073_2021-01-01   1073   jefferson county  alabama   \n",
       " 1349         1747   1073_2021-02-01   1073   jefferson county  alabama   \n",
       " 1350         1748   1073_2021-03-01   1073   jefferson county  alabama   \n",
       " 1351         1749   1073_2021-04-01   1073   jefferson county  alabama   \n",
       " 1352         1750   1073_2021-05-01   1073   jefferson county  alabama   \n",
       " ...           ...               ...    ...                ...      ...   \n",
       " 96966      150601  56037_2021-08-01  56037  sweetwater county  wyoming   \n",
       " 96967      150602  56037_2021-09-01  56037  sweetwater county  wyoming   \n",
       " 96968      150603  56037_2021-10-01  56037  sweetwater county  wyoming   \n",
       " 96969      150604  56037_2021-11-01  56037  sweetwater county  wyoming   \n",
       " 96970      150605  56037_2021-12-01  56037  sweetwater county  wyoming   \n",
       " \n",
       "       first_day_of_month  microbusiness_density year_month  year  month  \\\n",
       " 1348          2021-01-01               6.216286    2021-01  2021      1   \n",
       " 1349          2021-02-01               6.120514    2021-02  2021      2   \n",
       " 1350          2021-03-01               6.167122    2021-03  2021      3   \n",
       " 1351          2021-04-01               6.269579    2021-04  2021      4   \n",
       " 1352          2021-05-01               6.251881    2021-05  2021      5   \n",
       " ...                  ...                    ...        ...   ...    ...   \n",
       " 96966         2021-08-01               3.452806    2021-08  2021      8   \n",
       " 96967         2021-09-01               3.362107    2021-09  2021      9   \n",
       " 96968         2021-10-01               3.255770    2021-10  2021     10   \n",
       " 96969         2021-11-01               3.093138    2021-11  2021     11   \n",
       " 96970         2021-12-01               3.039970    2021-12  2021     12   \n",
       " \n",
       "        pct_bb  pct_college  pct_foreign_born  pct_it_workers  median_hh_inc  \\\n",
       " 1348     79.4         20.4               4.1             2.5          53901   \n",
       " 1349     79.4         20.4               4.1             2.5          53901   \n",
       " 1350     79.4         20.4               4.1             2.5          53901   \n",
       " 1351     79.4         20.4               4.1             2.5          53901   \n",
       " 1352     79.4         20.4               4.1             2.5          53901   \n",
       " ...       ...          ...               ...             ...            ...   \n",
       " 96966    84.0         14.8               4.7             1.0          74843   \n",
       " 96967    84.0         14.8               4.7             1.0          74843   \n",
       " 96968    84.0         14.8               4.7             1.0          74843   \n",
       " 96969    84.0         14.8               4.7             1.0          74843   \n",
       " 96970    84.0         14.8               4.7             1.0          74843   \n",
       " \n",
       "                region  region_code  state_code  \n",
       " 1348        southeast            5           1  \n",
       " 1349        southeast            5           1  \n",
       " 1350        southeast            5           1  \n",
       " 1351        southeast            5           1  \n",
       " 1352        southeast            5           1  \n",
       " ...               ...          ...         ...  \n",
       " 96966  rocky mountain            7          50  \n",
       " 96967  rocky mountain            7          50  \n",
       " 96968  rocky mountain            7          50  \n",
       " 96969  rocky mountain            7          50  \n",
       " 96970  rocky mountain            7          50  \n",
       " \n",
       " [12883 rows x 18 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e710af2",
   "metadata": {},
   "source": [
    "to partition the data based on the continuous target variable without converting it to a categorical variable, you can use regression trees instead of classification trees. RandomForestRegressor is the regression equivalent of RandomForestClassifier in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec13b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = ['pct_bb', 'pct_college', 'pct_foreign_born', 'median_hh_inc', 'pct_it_workers', 'cfips', 'region_code', 'state_code']\n",
    "target = 'microbusiness_density'\n",
    "\n",
    "# Create a Random Forest regressor model with 10 trees\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=92)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(merged_df_clean[features], merged_df_clean[target])\n",
    "\n",
    "# Predict the target variable for each row in the data\n",
    "y_pred = rf.predict(merged_df_clean[features])\n",
    "\n",
    "# Add the predicted target variable to the data\n",
    "merged_df_clean['y_pred'] = y_pred\n",
    "\n",
    "# Partition the data into smaller dataframes based on the predicted target variable\n",
    "dfs_rf = []\n",
    "for val, df in merged_df_clean.groupby(pd.cut(merged_df_clean['y_pred'], bins=10)):\n",
    "    dfs_rf.append(df.drop(columns=['y_pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731eabf4",
   "metadata": {},
   "source": [
    "Here, we create a RandomForestRegressor model with 10 trees, and fit it to the data using the 'microbusiness_density' variable. We use the model to predict the target variable for each row in the data, and add the predicted values as a new column in the dataframe.\n",
    "\n",
    "Then, we partition the data into smaller dataframes based on the predicted target variable using the groupby() method in pandas, and pd.cut() function to divide the range of predicted values into 10 bins. We drop the y_pred column from each dataframe before appending it to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds for the binary classification problem\n",
    "thresholds = [merged_df_clean[target].quantile(0.33), merged_df_clean[target].quantile(0.67)]\n",
    "\n",
    "# Loop over each partition\n",
    "for i, df in enumerate(dfs_dt):\n",
    "    print(f\"Partition {i}\")\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=92)\n",
    "\n",
    "    # Train a random forest classifier\n",
    "    rf = RandomForestRegressor(n_estimators=10, random_state=92)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Classify the predictions using the thresholds\n",
    "    y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "    # Calculate the accuracy, type 1 and type 2 errors, and confusion matrix\n",
    "    if np.sum(y_pred_class) == 0:\n",
    "        tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test >= thresholds[0], y_pred_class)}\")\n",
    "    print(f\"TPR: {tpr}, FPR: {fpr}\")\n",
    "    print(f\"Type 1 error: {fp / (tn + fp)}\")\n",
    "    print(f\"Type 2 error: {fn / (fn + tp)}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(y_test >= thresholds[0], y_pred_class)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9c44a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0\n",
      "Model: LGBM\n",
      "Accuracy: 0.8438102583879676\n",
      "SMAPE: 20.306180301144938\n",
      "TPR: 0.8440860215053764, FPR: 0.15639810426540285\n",
      "Type 1 error: 0.15639810426540285\n",
      "Type 2 error: 0.15591397849462366\n",
      "Confusion matrix:\n",
      "[[3738  693]\n",
      " [ 522 2826]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9096284869520503\n",
      "SMAPE: 11.75940928233866\n",
      "TPR: 0.9124850657108722, FPR: 0.09252990295644324\n",
      "Type 1 error: 0.09252990295644324\n",
      "Type 2 error: 0.08751493428912784\n",
      "Confusion matrix:\n",
      "[[4021  410]\n",
      " [ 293 3055]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9727471397351845\n",
      "SMAPE: 3.6139251529715\n",
      "TPR: 0.9716248506571087, FPR: 0.026404874746106973\n",
      "Type 1 error: 0.026404874746106973\n",
      "Type 2 error: 0.028375149342891277\n",
      "Confusion matrix:\n",
      "[[4314  117]\n",
      " [  95 3253]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.6400565625401723\n",
      "SMAPE: 34.618915319382225\n",
      "TPR: 0.6833930704898447, FPR: 0.3926878808395396\n",
      "Type 1 error: 0.3926878808395396\n",
      "Type 2 error: 0.31660692951015534\n",
      "Confusion matrix:\n",
      "[[2691 1740]\n",
      " [1060 2288]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.6342717572952822\n",
      "SMAPE: 34.93806684270428\n",
      "TPR: 0.6666666666666666, FPR: 0.3902053712480253\n",
      "Type 1 error: 0.3902053712480253\n",
      "Type 2 error: 0.3333333333333333\n",
      "Confusion matrix:\n",
      "[[2702 1729]\n",
      " [1116 2232]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.6856922483609719\n",
      "SMAPE: 32.32389894154523\n",
      "TPR: 0.7461170848267622, FPR: 0.35996389076957797\n",
      "Type 1 error: 0.35996389076957797\n",
      "Type 2 error: 0.25388291517323774\n",
      "Confusion matrix:\n",
      "[[2836 1595]\n",
      " [ 850 2498]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.6856922483609719\n",
      "SMAPE: 32.32390011004467\n",
      "TPR: 0.7461170848267622, FPR: 0.35996389076957797\n",
      "Type 1 error: 0.35996389076957797\n",
      "Type 2 error: 0.25388291517323774\n",
      "Confusion matrix:\n",
      "[[2836 1595]\n",
      " [ 850 2498]]\n",
      "\n",
      "Partition 1\n",
      "Model: LGBM\n",
      "Accuracy: 0.8471440064360418\n",
      "SMAPE: 17.410390770115402\n",
      "TPR: 0.9808102345415778, FPR: 0.5639344262295082\n",
      "Type 1 error: 0.5639344262295082\n",
      "Type 2 error: 0.019189765458422176\n",
      "Confusion matrix:\n",
      "[[ 532  688]\n",
      " [  72 3680]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9432823813354787\n",
      "SMAPE: 8.00433181855996\n",
      "TPR: 0.9848081023454158, FPR: 0.18442622950819673\n",
      "Type 1 error: 0.18442622950819673\n",
      "Type 2 error: 0.015191897654584221\n",
      "Confusion matrix:\n",
      "[[ 995  225]\n",
      " [  57 3695]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9802896218825422\n",
      "SMAPE: 3.2539371063431486\n",
      "TPR: 0.9898720682302772, FPR: 0.04918032786885246\n",
      "Type 1 error: 0.04918032786885246\n",
      "Type 2 error: 0.010127931769722815\n",
      "Confusion matrix:\n",
      "[[1160   60]\n",
      " [  38 3714]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.754827031375704\n",
      "SMAPE: 34.43970276681718\n",
      "TPR: 1.0, FPR: 0.9991803278688525\n",
      "Type 1 error: 0.9991803278688525\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   1 1219]\n",
      " [   0 3752]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.7546259050683829\n",
      "SMAPE: 35.941535985964144\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0 1220]\n",
      " [   0 3752]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.7670957361222848\n",
      "SMAPE: 32.46163635656927\n",
      "TPR: 0.990405117270789, FPR: 0.919672131147541\n",
      "Type 1 error: 0.919672131147541\n",
      "Type 2 error: 0.009594882729211088\n",
      "Confusion matrix:\n",
      "[[  98 1122]\n",
      " [  36 3716]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.7670957361222848\n",
      "SMAPE: 32.46160399677549\n",
      "TPR: 0.990405117270789, FPR: 0.919672131147541\n",
      "Type 1 error: 0.919672131147541\n",
      "Type 2 error: 0.009594882729211088\n",
      "Confusion matrix:\n",
      "[[  98 1122]\n",
      " [  36 3716]]\n",
      "\n",
      "Partition 2\n",
      "Model: LGBM\n",
      "Accuracy: 0.8883732291157792\n",
      "SMAPE: 16.34367987243351\n",
      "TPR: 0.9927388905024688, FPR: 0.663594470046083\n",
      "Type 1 error: 0.663594470046083\n",
      "Type 2 error: 0.007261109497531223\n",
      "Confusion matrix:\n",
      "[[ 219  432]\n",
      " [  25 3418]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9474841231069858\n",
      "SMAPE: 7.232079063779462\n",
      "TPR: 0.9875108916642463, FPR: 0.2642089093701997\n",
      "Type 1 error: 0.2642089093701997\n",
      "Type 2 error: 0.012489108335753703\n",
      "Confusion matrix:\n",
      "[[ 479  172]\n",
      " [  43 3400]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9814362481680508\n",
      "SMAPE: 3.170988806667623\n",
      "TPR: 0.9889631135637525, FPR: 0.05837173579109063\n",
      "Type 1 error: 0.05837173579109063\n",
      "Type 2 error: 0.01103688643624746\n",
      "Confusion matrix:\n",
      "[[ 613   38]\n",
      " [  38 3405]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.8409868099658037\n",
      "SMAPE: 37.766631558105786\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  651]\n",
      " [   0 3443]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.8409868099658037\n",
      "SMAPE: 38.7988942819885\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  651]\n",
      " [   0 3443]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.8431851489985345\n",
      "SMAPE: 34.60586265332106\n",
      "TPR: 0.9968051118210862, FPR: 0.9692780337941628\n",
      "Type 1 error: 0.9692780337941628\n",
      "Type 2 error: 0.003194888178913738\n",
      "Confusion matrix:\n",
      "[[  20  631]\n",
      " [  11 3432]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.8431851489985345\n",
      "SMAPE: 34.60579777243087\n",
      "TPR: 0.9968051118210862, FPR: 0.9692780337941628\n",
      "Type 1 error: 0.9692780337941628\n",
      "Type 2 error: 0.003194888178913738\n",
      "Confusion matrix:\n",
      "[[  20  631]\n",
      " [  11 3432]]\n",
      "\n",
      "Partition 3\n",
      "Model: LGBM\n",
      "Accuracy: 0.9755529685681025\n",
      "SMAPE: 8.18848746483556\n",
      "TPR: 0.996328029375765, FPR: 0.42857142857142855\n",
      "Type 1 error: 0.42857142857142855\n",
      "Type 2 error: 0.0036719706242350062\n",
      "Confusion matrix:\n",
      "[[  72   54]\n",
      " [   9 2442]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.9926270857586341\n",
      "SMAPE: 3.0235519383373974\n",
      "TPR: 0.9983680130558955, FPR: 0.11904761904761904\n",
      "Type 1 error: 0.11904761904761904\n",
      "Type 2 error: 0.0016319869441044472\n",
      "Confusion matrix:\n",
      "[[ 111   15]\n",
      " [   4 2447]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.996895615056267\n",
      "SMAPE: 2.0111335728330193\n",
      "TPR: 0.9983680130558955, FPR: 0.031746031746031744\n",
      "Type 1 error: 0.031746031746031744\n",
      "Type 2 error: 0.0016319869441044472\n",
      "Confusion matrix:\n",
      "[[ 122    4]\n",
      " [   4 2447]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.9511059371362048\n",
      "SMAPE: 30.271709216136426\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   0 2451]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.9511059371362048\n",
      "SMAPE: 30.732884684514328\n",
      "TPR: 1.0, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.0\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   0 2451]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.9491656965463717\n",
      "SMAPE: 27.36115729283564\n",
      "TPR: 0.9979600163198694, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.002039983680130559\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   5 2446]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.9491656965463717\n",
      "SMAPE: 27.360957058888026\n",
      "TPR: 0.9979600163198694, FPR: 1.0\n",
      "Type 1 error: 1.0\n",
      "Type 2 error: 0.002039983680130559\n",
      "Confusion matrix:\n",
      "[[   0  126]\n",
      " [   5 2446]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the thresholds for the binary classification problem\n",
    "thresholds = [merged_df_clean[target].quantile(0.33), merged_df_clean[target].quantile(0.67)]\n",
    "\n",
    "# Define a list of models to evaluate\n",
    "models = [('LGBM', LGBMRegressor(random_state=92)),\n",
    "          ('XGB', XGBRegressor(random_state=92)),\n",
    "          ('RandomForest', RandomForestRegressor(n_estimators=10, random_state=92)),\n",
    "          ('ElasticNet', ElasticNet(random_state=92)),\n",
    "          ('Lasso', Lasso(random_state=92)),\n",
    "          ('Ridge', Ridge(random_state=92)),\n",
    "          ('LinearRegression', LinearRegression())]\n",
    "\n",
    "# Loop over each partition\n",
    "for i, df in enumerate(dfs_dt):\n",
    "    print(f\"Partition {i}\")\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=92)\n",
    "    \n",
    "    # Loop over each model\n",
    "    for model_name, model in models:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the target variable for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Classify the predictions using the thresholds\n",
    "        y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "        # Calculate the evaluation metrics\n",
    "        if np.sum(y_pred_class) == 0:\n",
    "            tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        \n",
    "        # Calculate SMAPE\n",
    "        smape_score = smape(y_test, y_pred)\n",
    "        \n",
    "        \n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test >= thresholds[0], y_pred_class)}\")\n",
    "        print(f\"SMAPE: {smape_score}\")\n",
    "        print(f\"TPR: {tpr}, FPR: {fpr}\")\n",
    "        print(f\"Type 1 error: {fp / (tn + fp)}\")\n",
    "        print(f\"Type 2 error: {fn / (fn + tp)}\")\n",
    "        print(f\"Confusion matrix:\\n{confusion_matrix(y_test >= thresholds[0], y_pred_class)}\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99059670",
   "metadata": {},
   "source": [
    "We first define a list of models to evaluate, which includes the following algorithms: LGBM, XGB, RandomForest, ElasticNet, Lasso, Ridge, and LinearRegression. We then loop over each partition, and for each partition, we loop over each model, train the model on the training set, and make predictions on the test set. We then classify the predictions using the predefined thresholds, calculate the evaluation metrics, and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "039c1386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2655"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_clean['cfips'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f2a7a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Type 1 Error</th>\n",
       "      <th>Type 2 Error</th>\n",
       "      <th>SMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.870595</td>\n",
       "      <td>0.207041</td>\n",
       "      <td>0.207041</td>\n",
       "      <td>0.129405</td>\n",
       "      <td>20.306180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.904101</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>0.105613</td>\n",
       "      <td>0.105613</td>\n",
       "      <td>0.085284</td>\n",
       "      <td>11.759409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.972559</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.027441</td>\n",
       "      <td>3.613925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.640828</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.484490</td>\n",
       "      <td>0.484490</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>34.618915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.630672</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.490153</td>\n",
       "      <td>0.490153</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>34.938067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.684664</td>\n",
       "      <td>0.795265</td>\n",
       "      <td>0.416544</td>\n",
       "      <td>0.416544</td>\n",
       "      <td>0.204735</td>\n",
       "      <td>32.323899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.684664</td>\n",
       "      <td>0.795265</td>\n",
       "      <td>0.416544</td>\n",
       "      <td>0.416544</td>\n",
       "      <td>0.204735</td>\n",
       "      <td>32.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.852172</td>\n",
       "      <td>0.987378</td>\n",
       "      <td>0.629358</td>\n",
       "      <td>0.629358</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>17.410391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>0.228440</td>\n",
       "      <td>0.228440</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>8.004332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.984111</td>\n",
       "      <td>0.990469</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>3.253937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.780772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.439703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.780772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.941536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.789823</td>\n",
       "      <td>0.992272</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>32.461636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.789823</td>\n",
       "      <td>0.992272</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>32.461604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.994071</td>\n",
       "      <td>0.711957</td>\n",
       "      <td>0.711957</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>16.343680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.952369</td>\n",
       "      <td>0.988989</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>7.232079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.979726</td>\n",
       "      <td>0.989554</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>3.170989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.766632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.798894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>0.996612</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>34.605863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>0.996612</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>34.605798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.979045</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>8.188487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>3.023552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>0.997564</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>2.011134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.955763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.271709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.955763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.732885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.954986</td>\n",
       "      <td>0.999188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>27.361157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.954986</td>\n",
       "      <td>0.999188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>27.360957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Partition             Model  Accuracy       TPR       FPR  Type 1 Error  \\\n",
       "0           0              LGBM  0.830055  0.870595  0.207041      0.207041   \n",
       "1           0               XGB  0.904101  0.914716  0.105613      0.105613   \n",
       "2           0      RandomForest  0.971333  0.972559  0.029788      0.029788   \n",
       "3           0        ElasticNet  0.640828  0.777778  0.484490      0.484490   \n",
       "4           0             Lasso  0.630672  0.762712  0.490153      0.490153   \n",
       "5           0             Ridge  0.684664  0.795265  0.416544      0.416544   \n",
       "6           0  LinearRegression  0.684664  0.795265  0.416544      0.416544   \n",
       "7           1              LGBM  0.852172  0.987378  0.629358      0.629358   \n",
       "8           1               XGB  0.939260  0.986347  0.228440      0.228440   \n",
       "9           1      RandomForest  0.984111  0.990469  0.038532      0.038532   \n",
       "10          1        ElasticNet  0.780772  1.000000  1.000000      1.000000   \n",
       "11          1             Lasso  0.780772  1.000000  1.000000      1.000000   \n",
       "12          1             Ridge  0.789823  0.992272  0.931193      0.931193   \n",
       "13          1  LinearRegression  0.789823  0.992272  0.931193      0.931193   \n",
       "14          2              LGBM  0.898876  0.994071  0.711957      0.711957   \n",
       "15          2               XGB  0.952369  0.988989  0.282609      0.282609   \n",
       "16          2      RandomForest  0.979726  0.989554  0.083333      0.083333   \n",
       "17          2        ElasticNet  0.865169  1.000000  1.000000      1.000000   \n",
       "18          2             Lasso  0.865169  1.000000  1.000000      1.000000   \n",
       "19          2             Ridge  0.864436  0.996612  0.983696      0.983696   \n",
       "20          2  LinearRegression  0.864436  0.996612  0.983696      0.983696   \n",
       "21          3              LGBM  0.979045  0.999594  0.464912      0.464912   \n",
       "22          3               XGB  0.994567  0.999594  0.114035      0.114035   \n",
       "23          3      RandomForest  0.996896  0.997564  0.017544      0.017544   \n",
       "24          3        ElasticNet  0.955763  1.000000  1.000000      1.000000   \n",
       "25          3             Lasso  0.955763  1.000000  1.000000      1.000000   \n",
       "26          3             Ridge  0.954986  0.999188  1.000000      1.000000   \n",
       "27          3  LinearRegression  0.954986  0.999188  1.000000      1.000000   \n",
       "\n",
       "    Type 2 Error      SMAPE  \n",
       "0       0.129405  20.306180  \n",
       "1       0.085284  11.759409  \n",
       "2       0.027441   3.613925  \n",
       "3       0.222222  34.618915  \n",
       "4       0.237288  34.938067  \n",
       "5       0.204735  32.323899  \n",
       "6       0.204735  32.323900  \n",
       "7       0.012622  17.410391  \n",
       "8       0.013653   8.004332  \n",
       "9       0.009531   3.253937  \n",
       "10      0.000000  34.439703  \n",
       "11      0.000000  35.941536  \n",
       "12      0.007728  32.461636  \n",
       "13      0.007728  32.461604  \n",
       "14      0.005929  16.343680  \n",
       "15      0.011011   7.232079  \n",
       "16      0.010446   3.170989  \n",
       "17      0.000000  37.766632  \n",
       "18      0.000000  38.798894  \n",
       "19      0.003388  34.605863  \n",
       "20      0.003388  34.605798  \n",
       "21      0.000406   8.188487  \n",
       "22      0.000406   3.023552  \n",
       "23      0.002436   2.011134  \n",
       "24      0.000000  30.271709  \n",
       "25      0.000000  30.732885  \n",
       "26      0.000812  27.361157  \n",
       "27      0.000812  27.360957  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dataframe to store the results\n",
    "results_list = []\n",
    "\n",
    "# Define the thresholds for the binary classification problem\n",
    "thresholds = [merged_df_clean[target].quantile(0.30), merged_df_clean[target].quantile(0.70)]\n",
    "\n",
    "# Define a list of models to evaluate\n",
    "models = [('LGBM', LGBMRegressor(random_state=92)),\n",
    "          ('XGB', XGBRegressor(random_state=92)),\n",
    "          ('RandomForest', RandomForestRegressor(n_estimators=10, random_state=92)),\n",
    "          ('ElasticNet', ElasticNet(random_state=92)),\n",
    "          ('Lasso', Lasso(random_state=92)),\n",
    "          ('Ridge', Ridge(random_state=92)),\n",
    "          ('LinearRegression', LinearRegression())]\n",
    "\n",
    "# Loop over each partition\n",
    "for i, df in enumerate(dfs_dt):\n",
    "#    print(f\"Partition {i}\")\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=92)\n",
    "    \n",
    "    # Loop over each model\n",
    "    for model_name, model in models:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the target variable for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Classify the predictions using the thresholds\n",
    "        y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "        # Calculate the evaluation metrics\n",
    "        if np.sum(y_pred_class) == 0:\n",
    "            tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        type1_err = fp / (tn + fp)\n",
    "        type2_err = fn / (fn + tp)\n",
    "        \n",
    "        # Calculate SMAPE\n",
    "        smape_score = smape(y_test, y_pred)\n",
    "        \n",
    "        # Add the results to the list\n",
    "        results_list.append({'Partition': i,\n",
    "                             'Model': model_name,\n",
    "                             'Accuracy': accuracy_score(y_test >= thresholds[0], y_pred_class),\n",
    "                             'TPR': tpr,\n",
    "                             'FPR': fpr,\n",
    "                             'Type 1 Error': type1_err,\n",
    "                             'Type 2 Error': type2_err,\n",
    "                             'SMAPE': smape_score})\n",
    "\n",
    "# Create a dataframe from the results list\n",
    "results_df = pd.concat([pd.DataFrame.from_records([r]) for r in results_list], ignore_index=True)\n",
    "\n",
    "# Print the results dataframe\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2638df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM\n",
      "Accuracy: 0.8215756951596292\n",
      "SMAPE: 24.461656782882617\n",
      "TPR: 0.9474959612277868, FPR: 0.47397449155463633\n",
      "Type 1 error: 0.47397449155463633\n",
      "Type 2 error: 0.05250403877221325\n",
      "Confusion matrix:\n",
      "[[ 3052  2750]\n",
      " [  715 12903]]\n",
      "\n",
      "Model: XGB\n",
      "Accuracy: 0.8730690010298661\n",
      "SMAPE: 17.17386845964759\n",
      "TPR: 0.9554266412101631, FPR: 0.32023440193036884\n",
      "Type 1 error: 0.32023440193036884\n",
      "Type 2 error: 0.04457335878983698\n",
      "Confusion matrix:\n",
      "[[ 3944  1858]\n",
      " [  607 13011]]\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.9803295571575695\n",
      "SMAPE: 3.190121728977069\n",
      "TPR: 0.9872962255837862, FPR: 0.03602206135815236\n",
      "Type 1 error: 0.03602206135815236\n",
      "Type 2 error: 0.012703774416213835\n",
      "Confusion matrix:\n",
      "[[ 5593   209]\n",
      " [  173 13445]]\n",
      "\n",
      "Model: ElasticNet\n",
      "Accuracy: 0.7735839340885685\n",
      "SMAPE: 34.92263770110042\n",
      "TPR: 0.9478631223380819, FPR: 0.6354705274043433\n",
      "Type 1 error: 0.6354705274043433\n",
      "Type 2 error: 0.052136877661918046\n",
      "Confusion matrix:\n",
      "[[ 2115  3687]\n",
      " [  710 12908]]\n",
      "\n",
      "Model: Lasso\n",
      "Accuracy: 0.7646240988671472\n",
      "SMAPE: 36.560206270932646\n",
      "TPR: 0.9586576589807607, FPR: 0.6907962771458118\n",
      "Type 1 error: 0.6907962771458118\n",
      "Type 2 error: 0.04134234101923924\n",
      "Confusion matrix:\n",
      "[[ 1794  4008]\n",
      " [  563 13055]]\n",
      "\n",
      "Model: Ridge\n",
      "Accuracy: 0.7804840370751802\n",
      "SMAPE: 34.26222364111129\n",
      "TPR: 0.9230430312821266, FPR: 0.5541192692175112\n",
      "Type 1 error: 0.5541192692175112\n",
      "Type 2 error: 0.0769569687178734\n",
      "Confusion matrix:\n",
      "[[ 2587  3215]\n",
      " [ 1048 12570]]\n",
      "\n",
      "Model: LinearRegression\n",
      "Accuracy: 0.7804840370751802\n",
      "SMAPE: 34.2622449744924\n",
      "TPR: 0.9230430312821266, FPR: 0.5541192692175112\n",
      "Type 1 error: 0.5541192692175112\n",
      "Type 2 error: 0.0769569687178734\n",
      "Confusion matrix:\n",
      "[[ 2587  3215]\n",
      " [ 1048 12570]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the models on the whole dataset\n",
    "\n",
    "# Define the thresholds for the binary classification problem\n",
    "thresholds = [merged_df_clean[target].quantile(0.30), merged_df_clean[target].quantile(0.70)]\n",
    "\n",
    "# Define a list of models to evaluate\n",
    "models = [('LGBM', LGBMRegressor(random_state=92)),\n",
    "          ('XGB', XGBRegressor(random_state=92)),\n",
    "          ('RandomForest', RandomForestRegressor(n_estimators=10, random_state=92)),\n",
    "          ('ElasticNet', ElasticNet(random_state=92)),\n",
    "          ('Lasso', Lasso(random_state=92)),\n",
    "          ('Ridge', Ridge(random_state=92)),\n",
    "          ('LinearRegression', LinearRegression())]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df_clean[features], merged_df_clean[target], test_size=0.2, random_state=92)\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model in models:\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Classify the predictions using the thresholds\n",
    "    y_pred_class = np.where(y_pred >= thresholds[0], 1, 0)\n",
    "\n",
    "    # Calculate the evaluation metrics\n",
    "    if np.sum(y_pred_class) == 0:\n",
    "        tn, fp, fn, tp = 0, 0, np.sum(y_test), 0\n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test >= thresholds[0], y_pred_class).ravel()\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    # Calculate SMAPE\n",
    "    smape_score = smape(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test >= thresholds[0], y_pred_class)}\")\n",
    "    print(f\"SMAPE: {smape_score}\")\n",
    "    print(f\"TPR: {tpr}, FPR: {fpr}\")\n",
    "    print(f\"Type 1 error: {fp / (tn + fp)}\")\n",
    "    print(f\"Type 2 error: {fn / (fn + tp)}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(y_test >= thresholds[0], y_pred_class)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f62b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
